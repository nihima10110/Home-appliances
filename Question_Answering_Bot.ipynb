{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOCT/YsNFiJ6ZQZplIw9Gsk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nihima10110/Home-appliances/blob/main/Question_Answering_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Packages"
      ],
      "metadata": {
        "id": "oVNDgchaahKU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NvD90HlmX5OE"
      },
      "outputs": [],
      "source": [
        "!pip install langchain                       #Main Freamework\n",
        "!pip install langchain_community   #For loaders,tools and vecotrs\n",
        "!pip install langchain_core             #Prompts,documents,runnable\n",
        "!pip install langchain_ollama         #local LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and Pull Ollama"
      ],
      "metadata": {
        "id": "mF7WiIIkaq2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BMKLIbc3ZJYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launch Ollama in Background"
      ],
      "metadata": {
        "id": "nJaq-Ot4ax4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading      #run function parallel in background\n",
        "import subprocess  #contunue running\n",
        "import time              #pause the program\n",
        "\n",
        "def run_ollama_serve():\n",
        "  subprocess.Popen([\"ollama\",\"serve\"])\n",
        "\n",
        "thread=threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "time.sleep(5)\n",
        "\n"
      ],
      "metadata": {
        "id": "hCEus90IaWOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pulling the Embedding Model"
      ],
      "metadata": {
        "id": "uOSAP6i0mkoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5V2uk62Rmndz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull nomic-embed-text\n",
        "!ollama pull gemma3:4b"
      ],
      "metadata": {
        "id": "gbQc1X_lmtQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install faiss-cpu             #Facebook AI Similarity Search"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SBDP5h-JtPYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "_9lhuyE2tSom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model=SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#use to convert text into vector\n",
        "llm=ChatOllama(model=\"gemma3:4b\")\n",
        "#use for reolying the questins"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0GXO6G12t4-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks= [\n",
        "    \"The Eiffel Tower is located in Paris.\",\n",
        "    \"Python is a programming language used for data science.\",\n",
        "    \"OpenAI develops large language models like ChatGPT.\",\n",
        "    \"The Great Wall of China is visible from space.\",\n",
        "    \"Water boils at 100 degrees Celsius under standard conditions.\",\n",
        "    \"The mitochondrion is the powerhouse of the cell.\",\n",
        "    \"Mount Everest is the tallest mountain above sea level.\",\n",
        "    \"Shakespeare wrote Hamlet and Macbeth.\",\n",
        "    \"Tesla produces electric vehicles and solar products.\",\n",
        "    \"Amazon is a large online retailer founded by Jeff Bezos.\",\n",
        "    \"The Moon orbits the Earth approximately every 27.3 days.\",\n",
        "    \"The speed of light is about 299,792 kilometers per second.\",\n",
        "    \"Albert Einstein developed the theory of relativity.\",\n",
        "    \"Venus is the second planet from the Sun.\",\n",
        "    \"The Pacific Ocean is the largest and deepest ocean on Earth.\",\n",
        "    \"Bacteria are single-celled microorganisms.\",\n",
        "    \"The capital of Japan is Tokyo.\",\n",
        "    \"Photosynthesis occurs in the chloroplasts of plant cells.\",\n",
        "    \"Leonardo da Vinci painted the Mona Lisa.\",\n",
        "    \"Bitcoin is a decentralized digital currency.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "xab6P7pBu9R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_vectors=embedding_model.encode(chunks)\n",
        "#convert chunks into vectors\n",
        "index=faiss.IndexFlatL2(chunk_vectors.shape[1])\n",
        "#indexing all as small or large distance by using L2(Eucledian) distance\n",
        "index.add(np.array(chunk_vectors))\n",
        "# adds all the chunk vectors to the FAISS index for searching them later"
      ],
      "metadata": {
        "id": "S6Jl8fp8vEqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template=\"\"\"Use the following context to answer the questions:\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "Answer:\"\"\""
      ],
      "metadata": {
        "id": "mP6X11Eby1mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=PromptTemplate.from_template(prompt_template)\n",
        "chain=LLMChain(llm=llm,prompt=prompt)"
      ],
      "metadata": {
        "id": "nDXlAp5Azyju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"Where is the Eiffel Tower?\",\n",
        "    \"Who painted the Mona Lisa?\",\n",
        "    \"What does Tesla produce?\",\n",
        "    \"What is the speed of light?\",\n",
        "    \"Where does photosynthesis happen in plant cells?\"\n",
        "]"
      ],
      "metadata": {
        "id": "poPuVZBW10ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=[]"
      ],
      "metadata": {
        "id": "HdgbNCtH13y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question in questions:\n",
        "  question_vector=embedding_model.encode([question])\n",
        "  #Convert questions into vector\n",
        "  _,idx=index.search(np.array(question_vector), k=1)\n",
        "  #searching the most similar vector in FAISS that match with question\n",
        "  #k=1 means the first chunk\n",
        "  #_ is used for ignoring because the index.search gives two strings\n",
        "  #first one is distance and second one is indecies\n",
        "  #as we only need indecies so ignore the distance by using _\n",
        "  top_chunk=chunks[idx[0][0]]\n",
        "  #to find the top most chunk\n",
        "  #suppose chunk=[[2]] then idx[0]=[2] and idx[0][0]=2\n",
        "  answer=chain.run(context=top_chunk,question=question).strip()\n",
        "  #run the question and get the answer\n",
        "  result.append((question,top_chunk,answer))\n",
        "\n"
      ],
      "metadata": {
        "id": "sKjl7FEs4XGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (question, context, answer) in enumerate(result, 1):\n",
        "    print(f\"ðŸ§  Question {i}: {question}\")\n",
        "    print(f\"ðŸ“š Retrieved Context: {context}\")\n",
        "    print(f\"âœ… Answer: {answer}\")\n",
        "    print(\"-\" * 70)"
      ],
      "metadata": {
        "id": "CQCgE-jhwroA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}